{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "\n",
    "InputDBY = io.loadmat('InputDBY_118.mat')\n",
    "InputDBY=InputDBY['InputDBY']\n",
    "\n",
    "SimulationData = io.loadmat('SimulationData_118.mat')\n",
    "LastIterline=SimulationData['LastIterline']\n",
    "LastIterRU=SimulationData['LastIterRU']\n",
    "LastIterRD=SimulationData['LastIterRD']\n",
    "\n",
    "InputDBY=np.transpose(InputDBY, (3,0,1,2))\n",
    "LastIterline=np.transpose(LastIterline, (2,0,1))\n",
    "LastIterRU=np.transpose(LastIterRU, (2,0,1))\n",
    "LastIterRD=np.transpose(LastIterRD, (2,0,1))\n",
    "\n",
    "InputDBY=np.float32(InputDBY)\n",
    "LastIterline=np.float32(LastIterline)\n",
    "LastIterRU=np.float32(LastIterRU)\n",
    "LastIterRD=np.float32(LastIterRD)\n",
    "\n",
    "print(InputDBY.shape)\n",
    "print(LastIterline.shape)\n",
    "print(LastIterRU.shape)\n",
    "print(LastIterRD.shape)\n",
    "\n",
    "Nunits=54\n",
    "Nbus=118\n",
    "Nbranch=186\n",
    "Horizon=24\n",
    "\n",
    "n_scenario=5000\n",
    "n_train=4000\n",
    "n_test=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening input data for ANN\n",
    "D=InputDBY[0:,0:,0:24,0]\n",
    "C=InputDBY[0:,0:,0:24,1]\n",
    "T=InputDBY[0:,0:,0:24,2]\n",
    "\n",
    "print(D.shape)\n",
    "print(C.shape)\n",
    "print(T.shape)\n",
    "\n",
    "D=np.reshape(D,(n_scenario,Nbus*24),'F')\n",
    "C=np.reshape(C,(n_scenario,Nbus*24),'F')\n",
    "T=np.reshape(T,(n_scenario,Nbus*24),'F')\n",
    "\n",
    "print(D.shape)\n",
    "print(C.shape)\n",
    "print(T.shape)\n",
    "\n",
    "InputDBY=np.concatenate((D,C,T), axis=1)\n",
    "print(InputDBY.shape)\n",
    "\n",
    "#Flattening target data\n",
    "LastIterline=np.reshape(LastIterline,(n_scenario,Nbranch*24),'F')\n",
    "LastIterRU=np.reshape(LastIterRU,(n_scenario,Nunits*23),'F')\n",
    "LastIterRD=np.reshape(LastIterRD,(n_scenario,Nunits*23),'F')\n",
    "\n",
    "print(LastIterline.shape)\n",
    "print(LastIterRU.shape)\n",
    "print(LastIterRD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for training\n",
    "x_train=InputDBY[0:n_train,0:]\n",
    "y_train_line=LastIterline[0:n_train,0:]\n",
    "y_train_rampRU=LastIterRU[0:n_train,0:]\n",
    "y_train_rampRD=LastIterRD[0:n_train,0:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train_line.shape)\n",
    "print(y_train_rampRU.shape)\n",
    "print(y_train_rampRD.shape)\n",
    "\n",
    "#normalizing training data\n",
    "maxD=np.amax(x_train[0:,0:2832])\n",
    "maxC=np.amax(x_train[0:,2832:5664])\n",
    "maxT=np.amax(x_train[0:,5664:8496])\n",
    "x_train[0:,0:2832]=x_train[0:,0:2832]/maxD\n",
    "x_train[0:,2832:5664]=x_train[0:,2832:5664]/maxC\n",
    "x_train[0:,5664:8496]=x_train[0:,5664:8496]/maxT\n",
    "print(maxD)\n",
    "print(maxC)\n",
    "print(maxT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for testing\n",
    "x_test=InputDBY[n_train:,0:]\n",
    "y_test_line=LastIterline[n_train:,0:]\n",
    "y_test_rampRU=LastIterRU[n_train:,0:]\n",
    "y_test_rampRD=LastIterRD[n_train:,0:]\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test_line.shape)\n",
    "print(y_test_rampRU.shape)\n",
    "print(y_test_rampRD.shape)\n",
    "\n",
    "#normalizing training data\n",
    "maxD=np.amax(x_test[0:,0:2832])\n",
    "maxC=np.amax(x_test[0:,576:1152])\n",
    "maxT=np.amax(x_test[0:,1152:1728])\n",
    "x_test[0:,0:2832]=x_test[0:,0:2832]/maxD\n",
    "x_test[0:,2832:5664]=x_test[0:,2832:5664]/maxC\n",
    "x_test[0:,5664:8496]=x_test[0:,5664:8496]/maxT\n",
    "print(maxD)\n",
    "print(maxC)\n",
    "print(maxT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f2(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "    f2 = 5*p*r / (4*p+r+K.epsilon())\n",
    "    return K.mean(f2)\n",
    "\n",
    "def f2_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "    f2 = 5*p*r / (4*p+r+K.epsilon())\n",
    "    return 1 - K.mean(f2)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "custom_early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    min_delta=0.001, \n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "batch_size=500\n",
    "epoch=30\n",
    "lr=0.0001\n",
    "input_dim=8496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_line = Sequential()\n",
    "model_line.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "model_line.add(Dense(1024, activation='relu'))\n",
    "model_line.add(Dense(Nbranch*24, activation='sigmoid'))\n",
    "\n",
    "model_line.compile(loss=f2_loss, optimizer=Adam(lr), metrics=['accuracy',f2])   \n",
    "history_line =model_line.fit(x_train, y_train_line, batch_size=batch_size, epochs=epoch,verbose=1,validation_split=0.1)\n",
    "\n",
    "#model_line.save(\"model_line_118_DCT_ANN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rampRU = Sequential()\n",
    "model_rampRU.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "model_rampRU.add(Dense(256, activation='relu'))\n",
    "model_rampRU.add(Dense(Nunits*23, activation='sigmoid'))\n",
    "\n",
    "model_rampRU.compile(loss=f2_loss, optimizer=Adam(lr), metrics=['accuracy',f2])\n",
    "history_rampRU =model_rampRU.fit(x_train, y_train_rampRU, batch_size=batch_size, epochs=epoch,verbose=1,validation_split=0.1)\n",
    "\n",
    "#model_rampRU.save(\"model_rampRU_118_DCT_ANN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rampRD = Sequential()\n",
    "model_rampRD.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "model_rampRD.add(Dense(256, activation='relu'))\n",
    "model_rampRD.add(Dense(Nunits*23, activation='sigmoid'))\n",
    "\n",
    "model_rampRD.compile(loss=f2_loss, optimizer=Adam(lr), metrics=['accuracy',f2])\n",
    "history_rampRD =model_rampRD.fit(x_train, y_train_rampRD, batch_size=batch_size, epochs=epoch,verbose=1,validation_split=0.1)\n",
    "\n",
    "#model_rampRD.save(\"model_rampRD_118_DCT_ANN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history.history.keys())\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_line.history['loss'])\n",
    "plt.title('Model Training Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss_line'], loc='upper right')          \n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_rampRU.history['loss'])\n",
    "plt.title('Model Training Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss_rampRU'], loc='upper right')          \n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_rampRD.history['loss'])\n",
    "plt.title('Model Training Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss_rampRD'], loc='upper right')          \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction \n",
    "y_pred_line=model_line.predict(x_test)\n",
    "y_pred_rampRU=model_rampRU.predict(x_test)\n",
    "y_pred_rampRD=model_rampRD.predict(x_test)\n",
    "print(y_pred_line.shape)\n",
    "print(y_pred_rampRU.shape)\n",
    "print(y_pred_rampRD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "probability_fitering=np.array([0.999])\n",
    "\n",
    "#testing the Branch classifier\n",
    "y_test_line=np.reshape(y_test_line,np.size(y_test_line,0)*np.size(y_test_line,1),'c')\n",
    "y_pred_line=np.reshape(y_pred_line,np.size(y_pred_line,0)*np.size(y_pred_line,1),'c')\n",
    "\n",
    "y_pred_line[y_pred_line >= probability_fitering] = 1\n",
    "y_pred_line[y_pred_line < probability_fitering] = 0\n",
    "print(confusion_matrix(y_test_line, y_pred_line))\n",
    "\n",
    "#testing the Ramp Up classifier\n",
    "y_test_rampRU=np.reshape(y_test_rampRU,np.size(y_test_rampRU,0)*np.size(y_test_rampRU,1),'c')\n",
    "y_pred_rampRU=np.reshape(y_pred_rampRU,np.size(y_pred_rampRU,0)*np.size(y_pred_rampRU,1),'c')\n",
    "\n",
    "y_pred_rampRU[y_pred_rampRU >= probability_fitering] = 1\n",
    "y_pred_rampRU[y_pred_rampRU < probability_fitering] = 0\n",
    "print(confusion_matrix(y_test_rampRU, y_pred_rampRU))\n",
    "\n",
    "#testing the Ramp Down classifier\n",
    "y_test_rampRD=np.reshape(y_test_rampRD,np.size(y_test_rampRD,0)*np.size(y_test_rampRD,1),'c')\n",
    "y_pred_rampRD=np.reshape(y_pred_rampRD,np.size(y_pred_rampRD,0)*np.size(y_pred_rampRD,1),'c')\n",
    "\n",
    "y_pred_rampRD[y_pred_rampRD >= probability_fitering] = 1\n",
    "y_pred_rampRD[y_pred_rampRD < probability_fitering] = 0\n",
    "print(confusion_matrix(y_test_rampRD, y_pred_rampRD))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_rampRD, y_pred_rampRD).ravel()\n",
    "print(fn, fp)\n",
    "\n",
    "print(y_pred_line.shape)\n",
    "print(y_pred_rampRU.shape)\n",
    "print(y_pred_rampRD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouput data reshaping\n",
    "y_pred_line=np.reshape(y_pred_line,(n_test,Nbranch*24),'c')\n",
    "y_pred_rampRU=np.reshape(y_pred_rampRU,(n_test,Nunits*23),'c')\n",
    "y_pred_rampRD=np.reshape(y_pred_rampRD,(n_test,Nunits*23),'c')\n",
    "print(y_pred_line.shape)\n",
    "print(y_pred_rampRU.shape)\n",
    "print(y_pred_rampRD.shape)\n",
    "\n",
    "#Breaking each scenario into row and columns\n",
    "y_pred_line=np.reshape(y_pred_line,(n_test,Nbranch,24),'F')\n",
    "y_pred_rampRU=np.reshape(y_pred_rampRU,(n_test,Nunits,23),'F')\n",
    "y_pred_rampRD=np.reshape(y_pred_rampRD,(n_test,Nunits,23),'F')\n",
    "print(y_pred_line.shape)\n",
    "print(y_pred_rampRU.shape)\n",
    "print(y_pred_rampRD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the trained model\n",
    "#model_line.save(\"model_line_24_Last.h5\")\n",
    "#model_rampRU.save(\"model_rampRU_24_Last.h5\")\n",
    "#model_rampRD.save(\"model_rampRD_24_Last.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the predicted result back to image format\n",
    "#predicted_24 = {\"predicted_branch\": y_pred_line,\"predicted_rampRU\": y_pred_rampRU,\"predicted_rampRD\": y_pred_rampRD}\n",
    "#io.savemat(r'predicted_24.mat', predicted_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
